{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jndmk1TVPUyp"
   },
   "source": [
    "# CIFAR10 Training and quantization\n",
    "\n",
    "Project inspired by this [kaggle competition](https://www.kaggle.com/ektasharma/simple-cifar10-cnn-keras-code-with-88-accuracy#A-Simple-Keras-CNN-trained-on-CIFAR-10-dataset-with-over-88%-accuracy-(Without-Data-Augmentation). In this colab you will be driven through the training of a CNN for CIFAR10 classification task. The model is then exported for inference with tflite and quantized, prepared for the *GAPflow*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj6DcUxZAOse"
   },
   "source": [
    "### Used python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KNb0mejGAHCV"
   },
   "outputs": [],
   "source": [
    "from nntool.api import NNGraph\n",
    "from model_v1 import *\n",
    "from tqdm import tqdm\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ynH1CrIeC7l9",
    "outputId": "27185c8d-5330-4655-8353-8ab49cc6a76d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__, tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTon9QahBjz3"
   },
   "source": [
    "# Reading the CIFAR-10 dataset from Keras datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y73NtaTwAJGn",
    "outputId": "26ce625b-21aa-4153-ebf2-1103585b6fe4"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "train_images, train_labels = train_images[:10000], train_labels[:10000]\n",
    "test_images, test_labels = test_images[:1000], test_labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qnpbZeX8Ab08",
    "outputId": "afca2f22-80e7-4153-ca25-7b8bef0ac7e9"
   },
   "outputs": [],
   "source": [
    "# Checking the number of rows (records) and columns (features)\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uuLdAMSkBsQL",
    "outputId": "26fcf4ee-1c97-46b2-8663-f9b32151da1c"
   },
   "outputs": [],
   "source": [
    "# Checking the number of unique classes \n",
    "print(np.unique(train_labels))\n",
    "print(np.unique(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YoOBr90BtWH"
   },
   "outputs": [],
   "source": [
    "# Creating a list of all the class labels\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "id": "JwRU0I-sBuh3",
    "outputId": "45c3aa84-2f34-4c06-ef18-b9e3c6ab4c0f"
   },
   "outputs": [],
   "source": [
    "# Visualizing some of the images from the training dataset\n",
    "plt.figure(figsize=[10,10])\n",
    "for i in range (25):    # for first 25 images\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i][0]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mA408CROB8m3"
   },
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Convert input [0:255] to [-1:1] float\n",
    "\n",
    "Convert labels to one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HS36TpJBvrK"
   },
   "outputs": [],
   "source": [
    "# Converting the pixels data to float type\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "\n",
    "# Standardizing (255 is the total number of pixels an image can have)\n",
    "train_images = (train_images / 128) - 1.0\n",
    "test_images = (test_images / 128) - 1.0\n",
    "\n",
    "# One hot encoding the target class (labels)\n",
    "num_classes = 10\n",
    "train_labels = to_categorical(train_labels, num_classes)\n",
    "test_labels = to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uk9v8V2gCFXF",
    "outputId": "2568277e-f3cb-4eec-ce03-6fc7ad5bd197"
   },
   "outputs": [],
   "source": [
    "MODEL_VERSION = 4\n",
    "\n",
    "if MODEL_VERSION == 1:\n",
    "    model = model_v1()\n",
    "    model_name = \"v1\"\n",
    "elif MODEL_VERSION == 2:\n",
    "    model = model_v2()\n",
    "    model_name = \"v2\"\n",
    "elif MODEL_VERSION == 3:\n",
    "    model = model_v3()\n",
    "    model_name = \"v3\"\n",
    "elif MODEL_VERSION == 4:\n",
    "    model = model_v4()\n",
    "    model_name = \"v4\"\n",
    "\n",
    "# Checking the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgrXAkCkCRzL"
   },
   "source": [
    "# Compile and Train the model (or load the pretrained one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZL5RClrCN1h"
   },
   "outputs": [],
   "source": [
    "#checkpoint_path = \"gdrive/MyDrive/cifar10/saved_model/my_model\"\n",
    "checkpoint_path = f\"./checkpoints/saved_model_{model_name}/\"\n",
    "train_again = True\n",
    "\n",
    "if os.path.exists(checkpoint_path) and not train_again:\n",
    "    model = tf.keras.models.load_model(checkpoint_path)\n",
    "    history = None\n",
    "else:\n",
    "    model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "    history = model.fit(train_images, train_labels, batch_size=64, epochs=2, # Add more epochs to get better results\n",
    "                      validation_data=(test_images, test_labels))\n",
    "    model.save(checkpoint_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Predictions\n",
    "pred = model.predict(test_images)\n",
    "accuracy = 100 * np.sum(np.argmax(pred, 1) == np.argmax(test_labels, 1)) / len(test_labels)\n",
    "print(f\"Trained model Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfryV1T7EhYG"
   },
   "source": [
    "# Visualize training results\n",
    "\n",
    "Only available if you have trained the model in this session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxQKwWtEEjIP"
   },
   "outputs": [],
   "source": [
    "if history:\n",
    "    # Loss curve\n",
    "    plt.figure(figsize=[6,4])\n",
    "    plt.plot(history.history['loss'], 'black', linewidth=2.0)\n",
    "    plt.plot(history.history['val_loss'], 'green', linewidth=2.0)\n",
    "    plt.legend(['Training Loss', 'Validation Loss'], fontsize=14)\n",
    "    plt.xlabel('Epochs', fontsize=10)\n",
    "    plt.ylabel('Loss', fontsize=10)\n",
    "    plt.title('Loss Curves', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ox9LUAfEqR8"
   },
   "outputs": [],
   "source": [
    "if history:\n",
    "    # Accuracy curve\n",
    "    plt.figure(figsize=[6,4])\n",
    "    plt.plot(history.history['accuracy'], 'black', linewidth=2.0)\n",
    "    plt.plot(history.history['val_accuracy'], 'blue', linewidth=2.0)\n",
    "    plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=14)\n",
    "    plt.xlabel('Epochs', fontsize=10)\n",
    "    plt.ylabel('Accuracy', fontsize=10)\n",
    "    plt.title('Accuracy Curves', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDGTyZ-SEwQD"
   },
   "source": [
    "# See the model at work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 830
    },
    "id": "UaWOvQi4EycM",
    "outputId": "7d2b2819-32e0-4d5d-a0ce-1a68cf2b31f1"
   },
   "outputs": [],
   "source": [
    "# Plotting the Actual vs. Predicted results\n",
    "# Converting the predictions into label index \n",
    "pred_classes = np.argmax(pred, axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(5, 5, figsize=(15,15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in np.arange(0, 25):\n",
    "    axes[i].imshow((128*(test_images[i]+1)).astype(np.uint8))\n",
    "    axes[i].set_title(f\"True: {class_names[np.argmax(test_labels[i])]}\\nPredict: {class_names[pred_classes[i]]}\", color=\"r\" if class_names[np.argmax(test_labels[i])]!=class_names[pred_classes[i]] else \"b\")\n",
    "    axes[i].axis('off')\n",
    "    plt.subplots_adjust(wspace=1)\n",
    "    img = Image.fromarray(np.uint8(128*(test_images[i]+1)))\n",
    "    img.save(f\"samples/cifar_test_{i}_{np.argmax(test_labels[i])}.ppm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHnm2AaEFFLE"
   },
   "source": [
    "# Convert to tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhLXJ5mCFJ8W"
   },
   "outputs": [],
   "source": [
    "# Helper function to run inference on a TFLite model\n",
    "def test_tflite_model(tflite_file, test_images, test_labels):\n",
    "    # Initialize the interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "    predictions = np.zeros((len(test_images),), dtype=int)\n",
    "    for i, (test_image, test_label) in enumerate(tqdm(zip(test_images, test_labels), total=len(test_labels))):\n",
    "        # Check if the input type is quantized, then rescale input data to uint8\n",
    "        if input_details['dtype'] == np.uint8:\n",
    "            input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "            test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "        interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "        predictions[i] = output.argmax()\n",
    "\n",
    "    test_labels_not_one_hot = np.argmax(test_labels, 1)\n",
    "    accuracy = (np.sum(test_labels_not_one_hot == predictions) * 100) / len(test_images)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_file = pathlib.Path(f\"cifar10_model_{model_name}_fp32.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s_w0Bbs9FGjv",
    "outputId": "fcee918c-1e4b-45bd-e5ef-385c2ac6f226"
   },
   "outputs": [],
   "source": [
    "# Converting a tf.Keras model to a TensorFlow Lite model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the unquantized/float model:\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRlsyupjGFaa",
    "outputId": "0991c086-4d83-4088-a9cf-72bb90f37f26"
   },
   "outputs": [],
   "source": [
    "fp32_accuracy = test_tflite_model(tflite_model_file, test_images, test_labels)\n",
    "print(f\"\\nFloat model accuracy: {fp32_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VqlDQv9HlJP"
   },
   "source": [
    "## Quantize to int8\n",
    "\n",
    "We use post training integer quantization to quantize the model (https://www.tensorflow.org/lite/performance/post_training_integer_quant).\n",
    "\n",
    "Weights are quantized directly from their values (they are constants), activations on the other hand depend on the input data. Hence we need to provide a calibration dataset to the quantizer so that it can run inference on it and collect the statistics of each layer in order to quantize the values in those ranges, i.e. Layer1 -> [-3.0, 6.0], Layer2 -> [-1.0, 2.5], ...\n",
    "\n",
    "As calibration dataset we need representative data of our use case. They cannot be the testing set, we are \"learning\" the statistics so using test dataset would be cheating. A subset of the training is tipycally used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v4Vf9wK0GqZ0",
    "outputId": "e3c201f1-b413-4dea-e3e5-7c6bce8df55a"
   },
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_quant_model_file = pathlib.Path(\"model/cifar10_model_uint8.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the unquantized/float model:\n",
    "tflite_quant_model_file.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qm4RO-GIHCdW",
    "outputId": "6219c701-5212-463b-bb9f-8ed8839c0cd1"
   },
   "outputs": [],
   "source": [
    "quant_accuracy = test_tflite_model(tflite_quant_model_file, test_images[:1000], test_labels[:1000])\n",
    "print(f\"Quantized model accuracy: {quant_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNTool Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nntool_inference(graph, test_images, test_labels):\n",
    "    predictions = np.zeros((len(test_images),), dtype=int)\n",
    "    for i, (test_image, test_label) in enumerate(tqdm(zip(test_images, test_labels), total=len(test_labels))):\n",
    "        output = graph.execute([test_image], dequantize=True)\n",
    "        predictions[i] = output[-1][0].argmax()\n",
    "\n",
    "    test_labels_not_one_hot = np.argmax(test_labels, 1)\n",
    "    accuracy = (np.sum(test_labels_not_one_hot == predictions) * 100) / len(test_images)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLITE_PATH = \"model/cifar10_model_uint8.tflite\"\n",
    "NE16 = False\n",
    "G = NNGraph.load_graph(TFLITE_PATH, load_quantization=True)\n",
    "G.quantize(None, graph_options={\"use_ne16\": NE16, \"hwc\": True})\n",
    "G.adjust_order()\n",
    "G.fusions(\"scaled_match_group\")\n",
    "#G.draw(quant_labels=True, fusions=True, view=False, filepath=\"nntool_graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nntool_quant_accuracy = nntool_inference(G, test_images[:1000], test_labels[:1000])\n",
    "print(f\"Quantized model accuracy: {nntool_quant_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(TFLITE_PATH))\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "test_image = test_images[0]\n",
    "# Check if the input type is quantized, then rescale input data to uint8\n",
    "if input_details['dtype'] == np.uint8:\n",
    "    input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "    test_image = test_image / input_scale + input_zero_point\n",
    "test_image = np.expand_dims(test_images[0], axis=0).astype(input_details[\"dtype\"])\n",
    "\n",
    "interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "interpreter.invoke()\n",
    "output_scale, output_zero_point = output_details[\"quantization\"]\n",
    "tflite_output = (interpreter.get_tensor(output_details[\"index\"])[0] - output_zero_point) * output_scale\n",
    "\n",
    "nntool_output = G.execute([test_images[0]], dequantize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(nntool_output[-1][0])\n",
    "plt.plot(tflite_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantize in NNTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLITE_PATH = \"model/cifar10_model_uint8.tflite\"\n",
    "NE16 = True\n",
    "G = NNGraph.load_graph(TFLITE_PATH, load_quantization=True)\n",
    "\n",
    "stats = G.collect_statistics([np.array(data) for data in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100)])\n",
    "G.quantize(stats, graph_options={\"use_ne16\": NE16, \"hwc\": True})\n",
    "G.adjust_order()\n",
    "G.fusions(\"scaled_match_group\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nntool_quant_accuracy = nntool_inference(G, test_images[:1000], test_labels[:1000])\n",
    "print(f\"Quantized model accuracy: {nntool_quant_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G.qshow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CIFAR10_TFLITE.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
